{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "! pip install openai -q\n",
    "! pip install python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai pydub -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_1/hfb_ghvx10q00n235p7x9s4m0000gn/T/ipykernel_30206/3683541761.py:24: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(\"harvard.mp3\")\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "speech_file_path = \"harvard.wav\"\n",
    "response = client.audio.speech.create(\n",
    "  # model=\"tts-1\",\n",
    "  model=\"tts-1-hd\",\n",
    "  # voice=\"alloy\",\n",
    "  voice = \"echo\",\n",
    "  # voice = \"fable\",\n",
    "  # voice = \"onyx\",\n",
    "  # voice = \"nova\",\n",
    "  # voice = \"shimmer\",\n",
    "  input=\"Your time is limited, so don’t waste it living someone else’s life. Don’t be trapped by dogma — which is living with the results of other people’s thinking. Don’t let the noise of others’ opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition. They somehow already know what you truly want to become. Everything else is secondary...Stay Hungry. Stay Foolish.\"\n",
    ")\n",
    "\n",
    "\n",
    "response.stream_to_file(\"harvard.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_1/hfb_ghvx10q00n235p7x9s4m0000gn/T/ipykernel_4851/2205648268.py:9: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    }
   ],
   "source": [
    "speech_file_path = \"different_language.mp3\"\n",
    "\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"onyx\",\n",
    "    input=\"जिस चीज को आप चाहते हैं, उसमें असफल होना, जिस चीज को आप नहीं चाहते उसमें सफल होने से बेहतर है।\"\n",
    ")\n",
    "\n",
    "response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your time is limited, so don't waste it living someone else's life. Don't be trapped by dogma, which is living with the results of other people's thinking. Don't let the noise of others' opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition. They somehow already know what you truly want to become. Everything else is secondary. Stay hungry, stay foolish.\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_file= open(\"/Users/vinayak/AI/projects/voice-assistant-bot/harvard.mp3\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\",\n",
    "  response_format=\"text\", # Default output format is json,if want in json format, just comment out response format\n",
    "  file=audio_file\n",
    ")\n",
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Transcript:  It is better to be unsuccessful in what you want than to be successful in what you don't want.\n",
      "\n",
      "\n",
      "\n",
      "Original Transcript:  जिस चीज़ को आप चाहते हैं, उसमें असफल होना। जिस चीज़ को आप नहीं चाहते, उसमें सफल होने से बहतर है।\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audio_file= open(\"/Users/vinayak/AI/projects/voice-assistant-bot/different_language.mp3\", \"rb\")\n",
    "\n",
    "transcript = client.audio.translations.create(\n",
    "  model=\"whisper-1\",\n",
    "  response_format = \"text\",\n",
    "  file=audio_file\n",
    ")\n",
    "\n",
    "print(\"Translated Transcript: \", transcript)\n",
    "print(\"\\n\")\n",
    "\n",
    "original_transcript = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\",\n",
    "  response_format=\"text\",\n",
    "  file=audio_file\n",
    ")\n",
    "\n",
    "print(\"Original Transcript: \", original_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinayak/AI/projects/voice-assistant-bot/voice/lib/python3.10/site-packages/pydub/utils.py:198: RuntimeWarning: Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\n",
      "  warn(\"Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ffprobe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(response_speaker_2\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Combine the audio files using pydub\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m audio1 \u001b[38;5;241m=\u001b[39m \u001b[43mAudioSegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file_path_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m audio2 \u001b[38;5;241m=\u001b[39m AudioSegment\u001b[38;5;241m.\u001b[39mfrom_wav(audio_file_path_2)\n\u001b[1;32m     44\u001b[0m combined_audio \u001b[38;5;241m=\u001b[39m audio1 \u001b[38;5;241m+\u001b[39m AudioSegment\u001b[38;5;241m.\u001b[39msilent(duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m) \u001b[38;5;241m+\u001b[39m audio2\n",
      "File \u001b[0;32m~/AI/projects/voice-assistant-bot/voice/lib/python3.10/site-packages/pydub/audio_segment.py:808\u001b[0m, in \u001b[0;36mAudioSegment.from_wav\u001b[0;34m(cls, file, parameters)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_wav\u001b[39m(\u001b[38;5;28mcls\u001b[39m, file, parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI/projects/voice-assistant-bot/voice/lib/python3.10/site-packages/pydub/audio_segment.py:728\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 728\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[43mmediainfo_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_ahead_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_ahead_limit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[1;32m    730\u001b[0m     audio_streams \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreams\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    731\u001b[0m                      \u001b[38;5;28;01mif\u001b[39;00m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcodec_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/AI/projects/voice-assistant-bot/voice/lib/python3.10/site-packages/pydub/utils.py:274\u001b[0m, in \u001b[0;36mmediainfo_json\u001b[0;34m(filepath, read_ahead_limit)\u001b[0m\n\u001b[1;32m    271\u001b[0m         file\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    273\u001b[0m command \u001b[38;5;241m=\u001b[39m [prober, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-of\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m command_args\n\u001b[0;32m--> 274\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstdin_parameter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m output, stderr \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mstdin_data)\n\u001b[1;32m    276\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/AI/projects/voice-assistant-bot/voice/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m~/AI/projects/voice-assistant-bot/voice/lib/python3.10/subprocess.py:1863\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1862\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ffprobe'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Define the text for each speaker\n",
    "text_speaker_1 = \"Your time is limited, so don’t waste it living someone else’s life. Don’t be trapped by dogma — which is living with the results of other people’s thinking.\"\n",
    "text_speaker_2 = \"Don’t let the noise of others’ opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition. They somehow already know what you truly want to become. Everything else is secondary...Stay Hungry. Stay Foolish.\"\n",
    "\n",
    "# Generate speech for each speaker\n",
    "response_speaker_1 = client.audio.speech.create(\n",
    "    model=\"tts-1-hd\",\n",
    "    voice=\"echo\",\n",
    "    input=text_speaker_1\n",
    ")\n",
    "\n",
    "response_speaker_2 = client.audio.speech.create(\n",
    "    model=\"tts-1-hd\",\n",
    "    voice=\"fable\",\n",
    "    input=text_speaker_2\n",
    ")\n",
    "\n",
    "# Save the audio files\n",
    "audio_file_path_1 = \"speaker_1.wav\"\n",
    "audio_file_path_2 = \"speaker_2.wav\"\n",
    "\n",
    "with open(audio_file_path_1, \"wb\") as f:\n",
    "    f.write(response_speaker_1.content)\n",
    "\n",
    "with open(audio_file_path_2, \"wb\") as f:\n",
    "    f.write(response_speaker_2.content)\n",
    "\n",
    "# Combine the audio files using pydub\n",
    "audio1 = AudioSegment.from_wav(audio_file_path_1)\n",
    "audio2 = AudioSegment.from_wav(audio_file_path_2)\n",
    "\n",
    "combined_audio = audio1 + AudioSegment.silent(duration=500) + audio2\n",
    "\n",
    "# Export the combined audio to a file\n",
    "combined_audio.export(\"podcast.wav\", format=\"wav\")\n",
    "\n",
    "print(\"Podcast audio saved as podcast.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinayak/AI/projects/voice-assistant-bot/voice/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ffmpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m\n\u001b[1;32m     18\u001b[0m     language_code \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m\"\u001b[39m: result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage_code\u001b[39m\u001b[38;5;124m\"\u001b[39m: language_code,\n\u001b[1;32m     22\u001b[0m     }\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/vinayak/AI/projects/voice-assistant-bot/harvard.mp3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(audio_file, model_name, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mTranscribe an audio file using a speech-to-text model.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    A dictionary representing the transcript, including the segments, the language code, and the duration of the audio file.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_model(model_name, device)\n\u001b[0;32m---> 16\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m language_code \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m\"\u001b[39m: result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage_code\u001b[39m\u001b[38;5;124m\"\u001b[39m: language_code,\n\u001b[1;32m     22\u001b[0m }\n",
      "File \u001b[0;32m~/AI/projects/voice-assistant-bot/voice/lib/python3.10/site-packages/whisper/transcribe.py:122\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    119\u001b[0m     decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Pad 30-seconds of silence to the input audio, for slicing\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m mel \u001b[38;5;241m=\u001b[39m \u001b[43mlog_mel_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_SAMPLES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m content_frames \u001b[38;5;241m=\u001b[39m mel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m N_FRAMES\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decode_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/AI/projects/voice-assistant-bot/voice/lib/python3.10/site-packages/whisper/audio.py:140\u001b[0m, in \u001b[0;36mlog_mel_spectrogram\u001b[0;34m(audio, n_mels, padding, device)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(audio):\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 140\u001b[0m         audio \u001b[38;5;241m=\u001b[39m \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     audio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(audio)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/AI/projects/voice-assistant-bot/voice/lib/python3.10/site-packages/whisper/audio.py:58\u001b[0m, in \u001b[0;36mload_audio\u001b[0;34m(file, sr)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# fmt: on\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/AI/projects/voice-assistant-bot/voice/lib/python3.10/subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    501\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/AI/projects/voice-assistant-bot/voice/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m~/AI/projects/voice-assistant-bot/voice/lib/python3.10/subprocess.py:1863\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1862\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ffmpeg'"
     ]
    }
   ],
   "source": [
    "import whisper \n",
    "\n",
    "def transcribe(audio_file: str, model_name: str, device: str = \"cpu\"):\n",
    "    \"\"\"\n",
    "    Transcribe an audio file using a speech-to-text model.\n",
    "\n",
    "    Args:\n",
    "        audio_file: Path to the audio file to transcribe.\n",
    "        model_name: Name of the model to use for transcription.\n",
    "        device: The device to use for inference (e.g., \"cpu\" or \"cuda\").\n",
    "\n",
    "    Returns:\n",
    "        A dictionary representing the transcript, including the segments, the language code, and the duration of the audio file.\n",
    "    \"\"\"\n",
    "    model = whisper.load_model(model_name, device)\n",
    "    result = model.transcribe(audio_file)\n",
    "\n",
    "    language_code = result[\"language\"]\n",
    "    return {\n",
    "        \"segments\": result[\"segments\"],\n",
    "        \"language_code\": language_code,\n",
    "    }\n",
    "\n",
    "\n",
    "transcribe(audio_file = \"/Users/vinayak/AI/projects/voice-assistant-bot/harvard.mp3\" , model_name=\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in ./voice/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: torchaudio in ./voice/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in ./voice/lib/python3.10/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions in ./voice/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./voice/lib/python3.10/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in ./voice/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./voice/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./voice/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./voice/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/pyannote/pyannote-audio\n",
      "  Cloning https://github.com/pyannote/pyannote-audio to /private/var/folders/_1/hfb_ghvx10q00n235p7x9s4m0000gn/T/pip-req-build-sp87ft6r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/pyannote/pyannote-audio /private/var/folders/_1/hfb_ghvx10q00n235p7x9s4m0000gn/T/pip-req-build-sp87ft6r\n",
      "  Resolved https://github.com/pyannote/pyannote-audio to commit 286ea1a4e34e2dd7d7926f590e402dac1e17494b\n",
      "  Running command git submodule update --init --recursive -q\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: asteroid-filterbanks>=0.4 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (0.4.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (0.6.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.13.0 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (0.23.4)\n",
      "Requirement already satisfied: lightning>=2.0.1 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (2.3.1)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (2.3.0)\n",
      "Requirement already satisfied: pyannote.core>=5.0.0 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (5.0.0)\n",
      "Requirement already satisfied: pyannote.database>=5.0.1 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (5.1.0)\n",
      "Requirement already satisfied: pyannote.metrics>=3.2 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (3.2.1)\n",
      "Requirement already satisfied: pyannote.pipeline>=3.0.1 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (3.0.1)\n",
      "Requirement already satisfied: pytorch_metric_learning>=2.1.0 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (2.5.0)\n",
      "Requirement already satisfied: rich>=12.0.0 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (13.7.1)\n",
      "Requirement already satisfied: semver>=3.0.0 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (3.0.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (0.12.1)\n",
      "Collecting speechbrain>=1.0.0 (from pyannote.audio==3.3.1)\n",
      "  Downloading speechbrain-1.0.0-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: tensorboardX>=2.6 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (2.6.2.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (2.0.0)\n",
      "Requirement already satisfied: torch_audiomentations>=0.11.0 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (0.11.1)\n",
      "Collecting torchaudio>=2.2.0 (from pyannote.audio==3.3.1)\n",
      "  Downloading torchaudio-2.3.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in ./voice/lib/python3.10/site-packages (from pyannote.audio==3.3.1) (1.4.0.post0)\n",
      "Requirement already satisfied: numpy in ./voice/lib/python3.10/site-packages (from asteroid-filterbanks>=0.4->pyannote.audio==3.3.1) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions in ./voice/lib/python3.10/site-packages (from asteroid-filterbanks>=0.4->pyannote.audio==3.3.1) (4.12.2)\n",
      "Requirement already satisfied: filelock in ./voice/lib/python3.10/site-packages (from huggingface_hub>=0.13.0->pyannote.audio==3.3.1) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./voice/lib/python3.10/site-packages (from huggingface_hub>=0.13.0->pyannote.audio==3.3.1) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./voice/lib/python3.10/site-packages (from huggingface_hub>=0.13.0->pyannote.audio==3.3.1) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./voice/lib/python3.10/site-packages (from huggingface_hub>=0.13.0->pyannote.audio==3.3.1) (6.0.1)\n",
      "Requirement already satisfied: requests in ./voice/lib/python3.10/site-packages (from huggingface_hub>=0.13.0->pyannote.audio==3.3.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./voice/lib/python3.10/site-packages (from huggingface_hub>=0.13.0->pyannote.audio==3.3.1) (4.66.4)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in ./voice/lib/python3.10/site-packages (from lightning>=2.0.1->pyannote.audio==3.3.1) (0.11.3.post0)\n",
      "Requirement already satisfied: pytorch-lightning in ./voice/lib/python3.10/site-packages (from lightning>=2.0.1->pyannote.audio==3.3.1) (2.3.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in ./voice/lib/python3.10/site-packages (from omegaconf<3.0,>=2.1->pyannote.audio==3.3.1) (4.9.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in ./voice/lib/python3.10/site-packages (from pyannote.core>=5.0.0->pyannote.audio==3.3.1) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in ./voice/lib/python3.10/site-packages (from pyannote.core>=5.0.0->pyannote.audio==3.3.1) (1.14.0)\n",
      "Requirement already satisfied: pandas>=0.19 in ./voice/lib/python3.10/site-packages (from pyannote.database>=5.0.1->pyannote.audio==3.3.1) (2.2.2)\n",
      "Requirement already satisfied: typer>=0.12.1 in ./voice/lib/python3.10/site-packages (from pyannote.database>=5.0.1->pyannote.audio==3.3.1) (0.12.3)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in ./voice/lib/python3.10/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.3.1) (1.5.1)\n",
      "Requirement already satisfied: docopt>=0.6.2 in ./voice/lib/python3.10/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.3.1) (0.6.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in ./voice/lib/python3.10/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.3.1) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in ./voice/lib/python3.10/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.3.1) (3.9.0)\n",
      "Requirement already satisfied: sympy>=1.1 in ./voice/lib/python3.10/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.3.1) (1.12.1)\n",
      "Requirement already satisfied: optuna>=3.1 in ./voice/lib/python3.10/site-packages (from pyannote.pipeline>=3.0.1->pyannote.audio==3.3.1) (3.6.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./voice/lib/python3.10/site-packages (from rich>=12.0.0->pyannote.audio==3.3.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./voice/lib/python3.10/site-packages (from rich>=12.0.0->pyannote.audio==3.3.1) (2.18.0)\n",
      "Requirement already satisfied: cffi>=1.0 in ./voice/lib/python3.10/site-packages (from soundfile>=0.12.1->pyannote.audio==3.3.1) (1.16.0)\n",
      "Requirement already satisfied: hyperpyyaml in ./voice/lib/python3.10/site-packages (from speechbrain>=1.0.0->pyannote.audio==3.3.1) (1.2.2)\n",
      "Requirement already satisfied: joblib in ./voice/lib/python3.10/site-packages (from speechbrain>=1.0.0->pyannote.audio==3.3.1) (1.4.2)\n",
      "Requirement already satisfied: sentencepiece in ./voice/lib/python3.10/site-packages (from speechbrain>=1.0.0->pyannote.audio==3.3.1) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in ./voice/lib/python3.10/site-packages (from tensorboardX>=2.6->pyannote.audio==3.3.1) (5.27.2)\n",
      "Requirement already satisfied: networkx in ./voice/lib/python3.10/site-packages (from torch>=2.0.0->pyannote.audio==3.3.1) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./voice/lib/python3.10/site-packages (from torch>=2.0.0->pyannote.audio==3.3.1) (3.1.4)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in ./voice/lib/python3.10/site-packages (from torch_audiomentations>=0.11.0->pyannote.audio==3.3.1) (0.2.7)\n",
      "Requirement already satisfied: librosa>=0.6.0 in ./voice/lib/python3.10/site-packages (from torch_audiomentations>=0.11.0->pyannote.audio==3.3.1) (0.10.2.post1)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in ./voice/lib/python3.10/site-packages (from torch_audiomentations>=0.11.0->pyannote.audio==3.3.1) (1.2.4)\n",
      "Collecting torch>=2.0.0 (from pyannote.audio==3.3.1)\n",
      "  Using cached torch-2.3.1-cp310-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: pycparser in ./voice/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio==3.3.1) (2.22)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./voice/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.3.1) (3.9.5)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./voice/lib/python3.10/site-packages (from librosa>=0.6.0->torch_audiomentations>=0.11.0->pyannote.audio==3.3.1) (3.0.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./voice/lib/python3.10/site-packages (from librosa>=0.6.0->torch_audiomentations>=0.11.0->pyannote.audio==3.3.1) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./voice/lib/python3.10/site-packages (from librosa>=0.6.0->torch_audiomentations>=0.11.0->pyannote.audio==3.3.1) (0.60.0)\n",
      "Requirement already satisfied: pooch>=1.1 in ./voice/lib/python3.10/site-packages (from librosa>=0.6.0->torch_audiomentations>=0.11.0->pyannote.audio==3.3.1) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./voice/lib/python3.10/site-packages (from librosa>=0.6.0->torch_audiomentations>=0.11.0->pyannote.audio==3.3.1) (0.3.7)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in ./voice/lib/python3.10/site-packages (from librosa>=0.6.0->torch_audiomentations>=0.11.0->pyannote.audio==3.3.1) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./voice/lib/python3.10/site-packages (from librosa>=0.6.0->torch_audiomentations>=0.11.0->pyannote.audio==3.3.1) (1.0.8)\n",
      "Requirement already satisfied: setuptools in ./voice/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0.1->pyannote.audio==3.3.1) (69.5.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./voice/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio==3.3.1) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./voice/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.3.1) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./voice/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.3.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./voice/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.3.1) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./voice/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.3.1) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in ./voice/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.3.1) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./voice/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.3.1) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./voice/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.3.1) (2.9.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./voice/lib/python3.10/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.3.1) (1.13.2)\n",
      "Requirement already satisfied: colorlog in ./voice/lib/python3.10/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.3.1) (6.8.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in ./voice/lib/python3.10/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.3.1) (2.0.31)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./voice/lib/python3.10/site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio==3.3.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./voice/lib/python3.10/site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio==3.3.1) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./voice/lib/python3.10/site-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio==3.3.1) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./voice/lib/python3.10/site-packages (from sympy>=1.1->pyannote.metrics>=3.2->pyannote.audio==3.3.1) (1.3.0)\n",
      "Requirement already satisfied: primePy>=1.3 in ./voice/lib/python3.10/site-packages (from torch-pitch-shift>=1.2.2->torch_audiomentations>=0.11.0->pyannote.audio==3.3.1) (1.3)\n",
      "Requirement already satisfied: click>=8.0.0 in ./voice/lib/python3.10/site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio==3.3.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./voice/lib/python3.10/site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio==3.3.1) (1.5.4)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in ./voice/lib/python3.10/site-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio==3.3.1) (0.18.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./voice/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->pyannote.audio==3.3.1) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./voice/lib/python3.10/site-packages (from requests->huggingface_hub>=0.13.0->pyannote.audio==3.3.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./voice/lib/python3.10/site-packages (from requests->huggingface_hub>=0.13.0->pyannote.audio==3.3.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./voice/lib/python3.10/site-packages (from requests->huggingface_hub>=0.13.0->pyannote.audio==3.3.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./voice/lib/python3.10/site-packages (from requests->huggingface_hub>=0.13.0->pyannote.audio==3.3.1) (2024.6.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./voice/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.3.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./voice/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.3.1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./voice/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.3.1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./voice/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.3.1) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./voice/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.3.1) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./voice/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.3.1) (4.0.3)\n",
      "Requirement already satisfied: Mako in ./voice/lib/python3.10/site-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.3.1) (1.3.5)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./voice/lib/python3.10/site-packages (from numba>=0.51.0->librosa>=0.6.0->torch_audiomentations>=0.11.0->pyannote.audio==3.3.1) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./voice/lib/python3.10/site-packages (from pooch>=1.1->librosa>=0.6.0->torch_audiomentations>=0.11.0->pyannote.audio==3.3.1) (4.2.2)\n",
      "Requirement already satisfied: six>=1.5 in ./voice/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.3.1) (1.16.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in ./voice/lib/python3.10/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio==3.3.1) (0.2.8)\n",
      "Downloading speechbrain-1.0.0-py3-none-any.whl (760 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.1/760.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.3.1-cp310-cp310-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached torch-2.3.1-cp310-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "Building wheels for collected packages: pyannote.audio\n",
      "  Building wheel for pyannote.audio (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyannote.audio: filename=pyannote.audio-3.3.1-py2.py3-none-any.whl size=898660 sha256=046e77f45ca71dcda7fdd52fb97e5fed06c9da815854b83168e1e3efe05839fd\n",
      "  Stored in directory: /private/var/folders/_1/hfb_ghvx10q00n235p7x9s4m0000gn/T/pip-ephem-wheel-cache-30xst80v/wheels/14/eb/0b/70e8da0b31341059e1db53d49f7f3fd782a927f86824981bfd\n",
      "Successfully built pyannote.audio\n",
      "Installing collected packages: torch, torchaudio, speechbrain, pyannote.audio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.0\n",
      "    Uninstalling torch-2.0.0:\n",
      "      Successfully uninstalled torch-2.0.0\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.0.1\n",
      "    Uninstalling torchaudio-2.0.1:\n",
      "      Successfully uninstalled torchaudio-2.0.1\n",
      "  Attempting uninstall: speechbrain\n",
      "    Found existing installation: speechbrain 0.5.16\n",
      "    Uninstalling speechbrain-0.5.16:\n",
      "      Successfully uninstalled speechbrain-0.5.16\n",
      "  Attempting uninstall: pyannote.audio\n",
      "    Found existing installation: pyannote.audio 3.1.1\n",
      "    Uninstalling pyannote.audio-3.1.1:\n",
      "      Successfully uninstalled pyannote.audio-3.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "whisperspeech 0.8 requires speechbrain<1.0, but you have speechbrain 1.0.0 which is incompatible.\n",
      "torchvision 0.15.1 requires torch==2.0.0, but you have torch 2.3.1 which is incompatible.\n",
      "whisperx 3.1.5 requires pyannote.audio==3.1.1, but you have pyannote-audio 3.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pyannote.audio-3.3.1 speechbrain-1.0.0 torch-2.3.1 torchaudio-2.3.1\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/pyannote/pyannote-audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import CalledProcessError, run\n",
    "from pyannote.audio import Pipeline\n",
    "import os"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
